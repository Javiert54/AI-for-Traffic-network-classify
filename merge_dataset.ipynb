{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('setup.json', 'r') as f:\n",
    "    SETUP_JSON = json.load(f)\n",
    "DATASETS_PATH = SETUP_JSON['datasets_path'] # Path to the datasets,\n",
    "DATASETS_FOLDER = os.path.join(os.getcwd(), DATASETS_PATH) # Folder containing the datasets,\n",
    "DATASETS = glob.glob(os.path.join(DATASETS_FOLDER, '*.csv')) # List of datasets\n",
    "OUTPUT_CSV = SETUP_JSON['output_csv'] # Output CSV file\n",
    "OUTPUT_PARQUET = SETUP_JSON['output_parquet'] # Output CSV file\n",
    "N_ROWS = SETUP_JSON['n_rows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener todas las características diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [f\"{DATASETS_PATH}\\\\02-14-2018.csv\", f\"{DATASETS_PATH}\\\\02-15-2018.csv\", f\"{DATASETS_PATH}\\\\02-16-2018.csv\", f\"{DATASETS_PATH}\\\\02-21-2018.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label')\n",
      "('Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label')\n"
     ]
    }
   ],
   "source": [
    "unique_headers = set()\n",
    "for dataset in DATASETS:\n",
    "    df = pd.read_csv(dataset, nrows=1)\n",
    "    df_dtypes = df.dtypes.keys()\n",
    "    unique_headers.add(tuple(df_dtypes))\n",
    "for header in unique_headers:\n",
    "    print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label'): ['c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-20-2018.csv'], ('Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label'): ['c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-14-2018.csv', 'c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-15-2018.csv', 'c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-16-2018.csv', 'c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-21-2018.csv', 'c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-22-2018.csv', 'c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-23-2018.csv', 'c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-28-2018.csv', 'c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\03-01-2018.csv', 'c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\03-02-2018.csv']}\n"
     ]
    }
   ],
   "source": [
    "headers = {}\n",
    "for header in unique_headers:\n",
    "    datasets = []\n",
    "    for dataset in DATASETS:\n",
    "        df = pd.read_csv(dataset, nrows=1)\n",
    "        df_dtypes = df.dtypes.keys()\n",
    "        if tuple(df_dtypes) == header:\n",
    "            datasets.append(dataset)\n",
    "    headers[header] = datasets\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos con headers distintos: ['c:\\\\Users\\\\isard\\\\Desktop\\\\AI-for-Traffic-network-classify\\\\datasets\\\\02-20-2018.csv']\n"
     ]
    }
   ],
   "source": [
    "def find_datasets_with_same_header():\n",
    "    headers = {}\n",
    "    same_files = {}\n",
    "\n",
    "    for file in DATASETS:\n",
    "        with open(file, newline='', encoding='utf-8') as f:\n",
    "            header = tuple(next(csv.reader(f), None))\n",
    "            if header:\n",
    "                if header in headers:\n",
    "                    headers[header].append(file)\n",
    "                else:\n",
    "                    headers[header] = [file]\n",
    "    print(\"Archivos con headers distintos:\", tuple(headers.values())[1])\n",
    "    return tuple(headers.values())[0]\n",
    "\n",
    "DATASETS = find_datasets_with_same_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isard\\AppData\\Local\\Temp\\ipykernel_3528\\661668898.py:26: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('merged_output.csv')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.dtypes.Int64DType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mixed_types_columns\n\u001b[32m     26\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mmerged_output.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m mixed_types_columns = \u001b[43mmixed_types_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col, types \u001b[38;5;129;01min\u001b[39;00m mixed_types_columns.items():\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumna: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mmixed_types_columns\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     16\u001b[39m types = {}\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m df[col]:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     typeVal = \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     types[typeVal] = types.get(typeVal, \u001b[32m0\u001b[39m) + \u001b[32m1\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: 'numpy.dtypes.Int64DType' object is not callable"
     ]
    }
   ],
   "source": [
    "def mixed_types_columns(df):\n",
    "    \"\"\"\n",
    "    Recorre todas las columnas del DataFrame y devuelve un diccionario\n",
    "    con las columnas que contienen más de un tipo de dato.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame a analizar.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario con nombres de columnas como claves,\n",
    "              y otro diccionario con los tipos de datos y sus cantidades como valores.\n",
    "    \"\"\"\n",
    "    mixed_types_columns = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        types = {}\n",
    "        for val in df[col]:\n",
    "            typeVal = type(val)\n",
    "            types[typeVal] = types.get(typeVal, 0) + 1\n",
    "\n",
    "        if len(types) > 1:\n",
    "            mixed_types_columns[col] = types\n",
    "\n",
    "    return mixed_types_columns\n",
    "\n",
    "df = pd.read_csv('merged_output.csv')\n",
    "mixed_types_columns = mixed_types_columns(df)\n",
    "for col, types in mixed_types_columns.items():\n",
    "    print(f\"Columna: {col}\")\n",
    "    for typeVal, quantity in types.items():\n",
    "        print(f\"  type: {typeVal.__name__}, Cantidad: {quantity}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isard\\AppData\\Local\\Temp\\ipykernel_3528\\2725541326.py:16: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ds) if isinstance(ds, str) else ds\n",
      "C:\\Users\\isard\\AppData\\Local\\Temp\\ipykernel_3528\\2725541326.py:16: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ds) if isinstance(ds, str) else ds\n",
      "C:\\Users\\isard\\AppData\\Local\\Temp\\ipykernel_3528\\2725541326.py:16: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ds) if isinstance(ds, str) else ds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: Dst Port\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Protocol\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Flow Duration\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Tot Fwd Pkts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Tot Bwd Pkts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: TotLen Fwd Pkts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: TotLen Bwd Pkts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Pkt Len Max\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Pkt Len Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Pkt Len Mean\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Pkt Len Std\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Pkt Len Max\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Pkt Len Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Pkt Len Mean\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Pkt Len Std\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Flow Byts/s\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 378101\n",
      "    Tipo: str, Cantidad: 235003\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60438\n",
      "    Tipo: float, Cantidad: 270687\n",
      "\n",
      "Columna: Flow Pkts/s\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Flow IAT Mean\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Flow IAT Std\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Flow IAT Max\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Flow IAT Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd IAT Tot\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd IAT Mean\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 983039\n",
      "    Tipo: int, Cantidad: 57344\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd IAT Std\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd IAT Max\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd IAT Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd IAT Tot\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd IAT Mean\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 983039\n",
      "    Tipo: int, Cantidad: 57344\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd IAT Std\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd IAT Max\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd IAT Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd PSH Flags\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd PSH Flags\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd URG Flags\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd URG Flags\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Header Len\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Header Len\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Pkts/s\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Pkts/s\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Pkt Len Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Pkt Len Max\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Pkt Len Mean\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Pkt Len Std\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Pkt Len Var\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: FIN Flag Cnt\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: SYN Flag Cnt\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: RST Flag Cnt\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: PSH Flag Cnt\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: ACK Flag Cnt\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: URG Flag Cnt\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: CWE Flag Count\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: ECE Flag Cnt\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Down/Up Ratio\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Pkt Size Avg\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 983039\n",
      "    Tipo: int, Cantidad: 57344\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Seg Size Avg\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Seg Size Avg\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 991231\n",
      "    Tipo: int, Cantidad: 49152\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Byts/b Avg\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Pkts/b Avg\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Blk Rate Avg\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Byts/b Avg\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Pkts/b Avg\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Bwd Blk Rate Avg\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Subflow Fwd Pkts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Subflow Fwd Byts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Subflow Bwd Pkts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Subflow Bwd Byts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Init Fwd Win Byts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Init Bwd Win Byts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Act Data Pkts\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Fwd Seg Size Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Active Mean\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1015807\n",
      "    Tipo: float, Cantidad: 24576\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Active Std\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 65535\n",
      "    Tipo: int, Cantidad: 974848\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Active Max\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Active Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Idle Mean\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 24576\n",
      "    Tipo: int, Cantidad: 1015807\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Idle Std\n",
      "  Dataset #2:\n",
      "    Tipo: float, Cantidad: 172031\n",
      "    Tipo: int, Cantidad: 868352\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: float, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: float, Cantidad: 270336\n",
      "\n",
      "Columna: Idle Max\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n",
      "Columna: Idle Min\n",
      "  Dataset #2:\n",
      "    Tipo: int, Cantidad: 1040383\n",
      "    Tipo: str, Cantidad: 8192\n",
      "  Dataset #6:\n",
      "    Tipo: int, Cantidad: 376832\n",
      "    Tipo: str, Cantidad: 236272\n",
      "  Dataset #7:\n",
      "    Tipo: str, Cantidad: 60789\n",
      "    Tipo: int, Cantidad: 270336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def comparar_tipos_en_columnas(datasets):\n",
    "    \"\"\"\n",
    "    Compara los tipos de datos presentes en columnas comunes entre varios datasets.\n",
    "\n",
    "    Args:\n",
    "        datasets (list): Lista de rutas a archivos CSV o DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario con nombres de columnas como claves.\n",
    "              Cada valor es una lista con un resumen de los tipos múltiples detectados por dataset.\n",
    "    \"\"\"\n",
    "    columnas_con_tipos_multiples = {}\n",
    "\n",
    "    for i, ds in enumerate(datasets):\n",
    "        # Cargar dataset si es ruta, o usar directamente si es DataFrame\n",
    "        df = pd.read_csv(ds) if isinstance(ds, str) else ds\n",
    "\n",
    "        for columna in df.columns:\n",
    "            tipos = {}\n",
    "            for val in df[columna]:\n",
    "                tipo = type(val)\n",
    "                tipos[tipo] = tipos.get(tipo, 0) + 1\n",
    "\n",
    "            if len(tipos) > 1:\n",
    "                if columna not in columnas_con_tipos_multiples:\n",
    "                    columnas_con_tipos_multiples[columna] = []\n",
    "                columnas_con_tipos_multiples[columna].append({\n",
    "                    'dataset_index': i,\n",
    "                    'tipos': {t.__name__: c for t, c in tipos.items()}\n",
    "                })\n",
    "\n",
    "    return columnas_con_tipos_multiples\n",
    "\n",
    "columnas_multiples = comparar_tipos_en_columnas(DATASETS)\n",
    "for columna, problemas in columnas_multiples.items():\n",
    "    print(f\"Columna: {columna}\")\n",
    "    for problema in problemas:\n",
    "        print(f\"  Dataset #{problema['dataset_index']}:\")\n",
    "        for tipo, cantidad in problema['tipos'].items():\n",
    "            print(f\"    Tipo: {tipo}, Cantidad: {cantidad}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "Dst Port int64\n",
      "Protocol int64\n",
      "Timestamp object\n",
      "Flow Duration int64\n",
      "Tot Fwd Pkts int64\n",
      "Tot Bwd Pkts int64\n",
      "TotLen Fwd Pkts int64\n",
      "TotLen Bwd Pkts int64\n",
      "Fwd Pkt Len Max int64\n",
      "Fwd Pkt Len Min int64\n",
      "Fwd Pkt Len Mean float64\n",
      "Fwd Pkt Len Std float64\n",
      "Bwd Pkt Len Max int64\n",
      "Bwd Pkt Len Min int64\n",
      "Bwd Pkt Len Mean int64\n",
      "Bwd Pkt Len Std float64\n",
      "Flow Byts/s float64\n",
      "Flow Pkts/s float64\n",
      "Flow IAT Mean float64\n",
      "Flow IAT Std float64\n",
      "Flow IAT Max int64\n",
      "Flow IAT Min int64\n",
      "Fwd IAT Tot int64\n",
      "Fwd IAT Mean float64\n",
      "Fwd IAT Std float64\n",
      "Fwd IAT Max int64\n",
      "Fwd IAT Min int64\n",
      "Bwd IAT Tot int64\n",
      "Bwd IAT Mean float64\n",
      "Bwd IAT Std float64\n",
      "Bwd IAT Max int64\n",
      "Bwd IAT Min int64\n",
      "Fwd PSH Flags int64\n",
      "Bwd PSH Flags int64\n",
      "Fwd URG Flags int64\n",
      "Bwd URG Flags int64\n",
      "Fwd Header Len int64\n",
      "Bwd Header Len int64\n",
      "Fwd Pkts/s float64\n",
      "Bwd Pkts/s float64\n",
      "Pkt Len Min int64\n",
      "Pkt Len Max int64\n",
      "Pkt Len Mean float64\n",
      "Pkt Len Std float64\n",
      "Pkt Len Var float64\n",
      "FIN Flag Cnt int64\n",
      "SYN Flag Cnt int64\n",
      "RST Flag Cnt int64\n",
      "PSH Flag Cnt int64\n",
      "ACK Flag Cnt int64\n",
      "URG Flag Cnt int64\n",
      "CWE Flag Count int64\n",
      "ECE Flag Cnt int64\n",
      "Down/Up Ratio int64\n",
      "Pkt Size Avg float64\n",
      "Fwd Seg Size Avg float64\n",
      "Bwd Seg Size Avg int64\n",
      "Fwd Byts/b Avg int64\n",
      "Fwd Pkts/b Avg int64\n",
      "Fwd Blk Rate Avg int64\n",
      "Bwd Byts/b Avg int64\n",
      "Bwd Pkts/b Avg int64\n",
      "Bwd Blk Rate Avg int64\n",
      "Subflow Fwd Pkts int64\n",
      "Subflow Fwd Byts int64\n",
      "Subflow Bwd Pkts int64\n",
      "Subflow Bwd Byts int64\n",
      "Init Fwd Win Byts int64\n",
      "Init Bwd Win Byts int64\n",
      "Fwd Act Data Pkts int64\n",
      "Fwd Seg Size Min int64\n",
      "Active Mean int64\n",
      "Active Std int64\n",
      "Active Max int64\n",
      "Active Min int64\n",
      "Idle Mean int64\n",
      "Idle Std int64\n",
      "Idle Max int64\n",
      "Idle Min int64\n"
     ]
    }
   ],
   "source": [
    "columns_lengths = []\n",
    "\n",
    "# Obtener número de columnas por dataset\n",
    "for dataset in DATASETS:\n",
    "    columns_length = len(pd.read_csv(dataset, nrows=1).dtypes)\n",
    "    columns_lengths.append(columns_length)\n",
    "\n",
    "# Obtener grupo de características más largo\n",
    "for dataset in DATASETS:\n",
    "    df = pd.read_csv(dataset, nrows=1)\n",
    "    columns_length = len(df.dtypes)\n",
    "    if (columns_length == max(columns_lengths)):\n",
    "        X_columns = df.dtypes.to_dict()\n",
    "        X_columns.pop('Label')\n",
    "print(len(X_columns))\n",
    "for column, type in X_columns.items():\n",
    "    print(column, type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinar datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos todos los archivos CSV en un sólo dataframe y lo guardamos en formato CSV (para analizarlo con Tableau) y en formato Parquet (para su tratamiento con Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-14-2018.csv procesado: (50000, 80))\n",
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-15-2018.csv procesado: (50000, 80))\n",
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-16-2018.csv procesado: (50000, 80))\n",
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-21-2018.csv procesado: (50000, 80))\n",
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-22-2018.csv procesado: (50000, 80))\n",
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-23-2018.csv procesado: (50000, 80))\n",
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-28-2018.csv procesado: (50000, 80))\n",
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-01-2018.csv procesado: (50000, 80))\n",
      "Dataset c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-02-2018.csv procesado: (50000, 80))\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for dataset in DATASETS:\n",
    "    # Obtener las 10000 primeras filas del dataset\n",
    "    current_df = pd.read_csv(dataset, nrows=N_ROWS, dtype=str) # Leer en formato string\n",
    "    # Añadir columnas faltantes\n",
    "    for column in X_columns.keys():\n",
    "        if column not in current_df.columns:\n",
    "            current_df[column] = 0 # Rellenar columnas con ceros\n",
    "    print(f\"Dataset {dataset} procesado: {current_df.shape})\")\n",
    "    # Concatenar dataframe actual con el dataframe final\n",
    "    df = pd.concat([df, current_df], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportación de archivos JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar todas las columnas y sus tipos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"X_columns = {col: str(dtype) for col, dtype in X_columns.items()}\\n\\n# Guardar en JSON\\nwith open('X_columns.json', 'w') as f:\\n    json.dump(X_columns, f, indent=4)\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_columns = {col: str(dtype) for col, dtype in X_columns.items()}\n",
    "\n",
    "# Guardar en JSON\n",
    "with open('X_columns.json', 'w') as f:\n",
    "    json.dump(X_columns, f, indent=4)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:31:01</td>\n",
       "      <td>112641719</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320859.5</td>\n",
       "      <td>139.3000358938</td>\n",
       "      <td>56320958</td>\n",
       "      <td>56320761</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:33:50</td>\n",
       "      <td>112641466</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320733</td>\n",
       "      <td>114.5512985522</td>\n",
       "      <td>56320814</td>\n",
       "      <td>56320652</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:36:39</td>\n",
       "      <td>112638623</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56319311.5</td>\n",
       "      <td>301.9345955667</td>\n",
       "      <td>56319525</td>\n",
       "      <td>56319098</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>14/02/2018 08:40:13</td>\n",
       "      <td>6453966</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1239</td>\n",
       "      <td>2273</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>14/02/2018 08:40:23</td>\n",
       "      <td>8804066</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1143</td>\n",
       "      <td>2209</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dst Port Protocol            Timestamp Flow Duration Tot Fwd Pkts  \\\n",
       "0        0        0  14/02/2018 08:31:01     112641719            3   \n",
       "1        0        0  14/02/2018 08:33:50     112641466            3   \n",
       "2        0        0  14/02/2018 08:36:39     112638623            3   \n",
       "3       22        6  14/02/2018 08:40:13       6453966           15   \n",
       "4       22        6  14/02/2018 08:40:23       8804066           14   \n",
       "\n",
       "  Tot Bwd Pkts TotLen Fwd Pkts TotLen Bwd Pkts Fwd Pkt Len Max  \\\n",
       "0            0               0               0               0   \n",
       "1            0               0               0               0   \n",
       "2            0               0               0               0   \n",
       "3           10            1239            2273             744   \n",
       "4           11            1143            2209             744   \n",
       "\n",
       "  Fwd Pkt Len Min  ... Fwd Seg Size Min Active Mean Active Std Active Max  \\\n",
       "0               0  ...                0           0          0          0   \n",
       "1               0  ...                0           0          0          0   \n",
       "2               0  ...                0           0          0          0   \n",
       "3               0  ...               32           0          0          0   \n",
       "4               0  ...               32           0          0          0   \n",
       "\n",
       "  Active Min   Idle Mean        Idle Std  Idle Max  Idle Min   Label  \n",
       "0          0  56320859.5  139.3000358938  56320958  56320761  Benign  \n",
       "1          0    56320733  114.5512985522  56320814  56320652  Benign  \n",
       "2          0  56319311.5  301.9345955667  56319525  56319098  Benign  \n",
       "3          0           0               0         0         0  Benign  \n",
       "4          0           0               0         0         0  Benign  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Obtener todas las etiquetas únicas del dataframe\n",
    "\n",
    "labels_list = list(df['Label'].unique())\n",
    "print(labels_list.remove('Label'))\n",
    "\n",
    "\n",
    "# Asignar índice a cada etiqueta\n",
    "labels = {}\n",
    "for i, label in enumerate(labels_list):\n",
    "    labels[label] = i\n",
    "\n",
    "# Guardar etiquetas en JSON\n",
    "with open('labels.json', 'w') as f:\n",
    "    json.dump(labels, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportación del dataframe en CSV y Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:31:01</td>\n",
       "      <td>112641719</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320859.5</td>\n",
       "      <td>139.3000358938</td>\n",
       "      <td>56320958</td>\n",
       "      <td>56320761</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:33:50</td>\n",
       "      <td>112641466</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320733</td>\n",
       "      <td>114.5512985522</td>\n",
       "      <td>56320814</td>\n",
       "      <td>56320652</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:36:39</td>\n",
       "      <td>112638623</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56319311.5</td>\n",
       "      <td>301.9345955667</td>\n",
       "      <td>56319525</td>\n",
       "      <td>56319098</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>14/02/2018 08:40:13</td>\n",
       "      <td>6453966</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1239</td>\n",
       "      <td>2273</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>14/02/2018 08:40:23</td>\n",
       "      <td>8804066</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1143</td>\n",
       "      <td>2209</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449995</th>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 11:30:58</td>\n",
       "      <td>9722</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>326</td>\n",
       "      <td>129</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449996</th>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 11:30:58</td>\n",
       "      <td>525</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449997</th>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 11:30:58</td>\n",
       "      <td>12784</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>326</td>\n",
       "      <td>129</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449998</th>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 11:30:58</td>\n",
       "      <td>708</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449999</th>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 11:30:59</td>\n",
       "      <td>9472</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>326</td>\n",
       "      <td>129</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450000 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dst Port Protocol            Timestamp Flow Duration Tot Fwd Pkts  \\\n",
       "0             0        0  14/02/2018 08:31:01     112641719            3   \n",
       "1             0        0  14/02/2018 08:33:50     112641466            3   \n",
       "2             0        0  14/02/2018 08:36:39     112638623            3   \n",
       "3            22        6  14/02/2018 08:40:13       6453966           15   \n",
       "4            22        6  14/02/2018 08:40:23       8804066           14   \n",
       "...         ...      ...                  ...           ...          ...   \n",
       "449995     8080        6  02/03/2018 11:30:58          9722            3   \n",
       "449996     8080        6  02/03/2018 11:30:58           525            2   \n",
       "449997     8080        6  02/03/2018 11:30:58         12784            3   \n",
       "449998     8080        6  02/03/2018 11:30:58           708            2   \n",
       "449999     8080        6  02/03/2018 11:30:59          9472            3   \n",
       "\n",
       "       Tot Bwd Pkts TotLen Fwd Pkts TotLen Bwd Pkts Fwd Pkt Len Max  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                10            1239            2273             744   \n",
       "4                11            1143            2209             744   \n",
       "...             ...             ...             ...             ...   \n",
       "449995            4             326             129             326   \n",
       "449996            0               0               0               0   \n",
       "449997            4             326             129             326   \n",
       "449998            0               0               0               0   \n",
       "449999            4             326             129             326   \n",
       "\n",
       "       Fwd Pkt Len Min  ... Fwd Seg Size Min Active Mean Active Std  \\\n",
       "0                    0  ...                0           0          0   \n",
       "1                    0  ...                0           0          0   \n",
       "2                    0  ...                0           0          0   \n",
       "3                    0  ...               32           0          0   \n",
       "4                    0  ...               32           0          0   \n",
       "...                ...  ...              ...         ...        ...   \n",
       "449995               0  ...               20           0          0   \n",
       "449996               0  ...               20           0          0   \n",
       "449997               0  ...               20           0          0   \n",
       "449998               0  ...               20           0          0   \n",
       "449999               0  ...               20           0          0   \n",
       "\n",
       "       Active Max Active Min   Idle Mean        Idle Std  Idle Max  Idle Min  \\\n",
       "0               0          0  56320859.5  139.3000358938  56320958  56320761   \n",
       "1               0          0    56320733  114.5512985522  56320814  56320652   \n",
       "2               0          0  56319311.5  301.9345955667  56319525  56319098   \n",
       "3               0          0           0               0         0         0   \n",
       "4               0          0           0               0         0         0   \n",
       "...           ...        ...         ...             ...       ...       ...   \n",
       "449995          0          0           0               0         0         0   \n",
       "449996          0          0           0               0         0         0   \n",
       "449997          0          0           0               0         0         0   \n",
       "449998          0          0           0               0         0         0   \n",
       "449999          0          0           0               0         0         0   \n",
       "\n",
       "         Label  \n",
       "0       Benign  \n",
       "1       Benign  \n",
       "2       Benign  \n",
       "3       Benign  \n",
       "4       Benign  \n",
       "...        ...  \n",
       "449995     Bot  \n",
       "449996     Bot  \n",
       "449997     Bot  \n",
       "449998     Bot  \n",
       "449999     Bot  \n",
       "\n",
       "[450000 rows x 80 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV guardado como merged_output.csv\n",
      "Archivo Parquet guardado como merged_output.parquet\n"
     ]
    }
   ],
   "source": [
    "# Guardar en CSV\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Archivo CSV guardado como {OUTPUT_CSV}\")\n",
    "\n",
    "# Guardar en Parquet\n",
    "df.to_parquet(OUTPUT_PARQUET, index=False)\n",
    "print(f\"Archivo Parquet guardado como {OUTPUT_PARQUET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_datasets_with_same_header():\n",
    "    headers = {}\n",
    "    same_files = {}\n",
    "\n",
    "    for file in DATASETS:\n",
    "        with open(file, newline='', encoding='utf-8') as f:\n",
    "            header = tuple(next(csv.reader(f), None))\n",
    "            if header:\n",
    "                if header in headers:\n",
    "                    headers[header].append(\"datasets\\\\\"+file)\n",
    "                else:\n",
    "                    headers[header] = [\"datasets\\\\\"+file]\n",
    "    print(\"Archivos con headers distintos:\", tuple(headers.values())[1])\n",
    "    return tuple(headers.values())[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

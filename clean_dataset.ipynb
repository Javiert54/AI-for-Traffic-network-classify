{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('setup.json', 'r') as f:\n",
    "    SETUP_JSON = json.load(f)\n",
    "DATASETS_PATH = SETUP_JSON['datasets_path'] # Path to the datasets,\n",
    "DATASETS_FOLDER = os.path.join(os.getcwd(), DATASETS_PATH) # Folder containing the datasets,\n",
    "DATASETS = glob.glob(os.path.join(DATASETS_FOLDER, '*.csv')) # List of datasets\n",
    "OUTPUT_CSV = SETUP_JSON['dataset_csv'] # Output CSV file\n",
    "OUTPUT_PARQUET = SETUP_JSON['dataset_parquet'] # Output CSV file\n",
    "N_ROWS = SETUP_JSON['n_rows']\n",
    "HEADER = SETUP_JSON['header']\n",
    "with open(HEADER, 'r') as f:\n",
    "    HEADER_JSON = json.load(f)\n",
    "NA_VAL = SETUP_JSON['navalues']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de los datasets a combinar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener todos los encabezados diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label')\n",
      "('Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label')\n"
     ]
    }
   ],
   "source": [
    "unique_headers = set()\n",
    "for dataset in DATASETS:\n",
    "    df = pd.read_csv(dataset, nrows=1)\n",
    "    df_dtypes = df.dtypes.keys()\n",
    "    unique_headers.add(tuple(df_dtypes))\n",
    "for header in unique_headers:\n",
    "    print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar los grupos de datasets por encabezados diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo de datasets:\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-14-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-15-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-16-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-21-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-22-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-23-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-28-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-01-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-02-2018.csv\n",
      "Número de columnas del grupo de datasets: 80\n",
      "\n",
      "Grupo de datasets:\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-20-2018.csv\n",
      "Número de columnas del grupo de datasets: 84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_by_header = {}\n",
    "for header in unique_headers:\n",
    "    datasets_group = []\n",
    "    for dataset in DATASETS:\n",
    "        df = pd.read_csv(dataset, nrows=1)\n",
    "        df_dtypes = df.dtypes.keys()\n",
    "        if tuple(df_dtypes) == header:\n",
    "            datasets_group.append(dataset)\n",
    "    datasets_by_header[header] = datasets_group\n",
    "    print(f\"Grupo de datasets:\")\n",
    "    for dataset in datasets_group:\n",
    "        print(dataset)\n",
    "    print(f\"Número de columnas del grupo de datasets: {len(header)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar los grupos de datasets por etiquetas diferentes encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo de datasets:\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-14-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-15-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-16-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-21-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-22-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-23-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-28-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-01-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-02-2018.csv\n",
      "Etiquetas diferentes encontradas:  {'Bot', 'FTP-BruteForce', 'Label', 'SQL Injection', 'DoS attacks-GoldenEye', 'DoS attacks-Slowloris', 'Brute Force -XSS', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Hulk', 'DDOS attack-HOIC', 'Brute Force -Web', 'Infilteration', 'DDOS attack-LOIC-UDP', 'Benign', 'SSH-Bruteforce'}\n",
      "\n",
      "Grupo de datasets:\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-20-2018.csv\n",
      "Etiquetas diferentes encontradas:  {'DDoS attacks-LOIC-HTTP', 'Benign'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_by_num_labels = {}\n",
    "\n",
    "for datasets_group in datasets_by_header.values():\n",
    "    unique_labels = set()\n",
    "    for dataset in datasets_group:\n",
    "        df = pd.read_csv(dataset, dtype=str)\n",
    "        last_column = df.columns[-1]  # Obtiene el nombre de la última columna\n",
    "        for label in list(df[last_column]):  # Usa la última columna en lugar de \"Label\"\n",
    "            unique_labels.add(label)\n",
    "    datasets_by_num_labels[tuple(datasets_group)] = len(unique_labels)\n",
    "    print(f\"Grupo de datasets:\")\n",
    "    for dataset in datasets_group:\n",
    "        print(dataset)\n",
    "    print(f\"Etiquetas diferentes encontradas: \", unique_labels)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionar el grupo de datasets que abarca más etiquetas diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selección de datasets a procesar:\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-14-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-15-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-16-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-21-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-22-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-23-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-28-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-01-2018.csv\n",
      "c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-02-2018.csv\n"
     ]
    }
   ],
   "source": [
    "for datasets_group, num_labels in datasets_by_num_labels.items():\n",
    "    if (num_labels) == max(datasets_by_num_labels.values()):\n",
    "        datasets_selected = datasets_group\n",
    "print(f\"Selección de datasets a procesar:\")\n",
    "for dataset in datasets_selected:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionar encabezado de los datasets a combinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar encabezado de los datasets a combinar\n",
    "x_columns = pd.read_csv(datasets_selected[0], nrows=1).dtypes.to_dict()\n",
    "x_columns.pop('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dst Port int64\n",
      "Protocol int64\n",
      "Timestamp object\n",
      "Flow Duration int64\n",
      "Tot Fwd Pkts int64\n",
      "Tot Bwd Pkts int64\n",
      "TotLen Fwd Pkts int64\n",
      "TotLen Bwd Pkts int64\n",
      "Fwd Pkt Len Max int64\n",
      "Fwd Pkt Len Min int64\n",
      "Fwd Pkt Len Mean int64\n",
      "Fwd Pkt Len Std int64\n",
      "Bwd Pkt Len Max int64\n",
      "Bwd Pkt Len Min int64\n",
      "Bwd Pkt Len Mean int64\n",
      "Bwd Pkt Len Std int64\n",
      "Flow Byts/s int64\n",
      "Flow Pkts/s float64\n",
      "Flow IAT Mean float64\n",
      "Flow IAT Std float64\n",
      "Flow IAT Max int64\n",
      "Flow IAT Min int64\n",
      "Fwd IAT Tot int64\n",
      "Fwd IAT Mean float64\n",
      "Fwd IAT Std float64\n",
      "Fwd IAT Max int64\n",
      "Fwd IAT Min int64\n",
      "Bwd IAT Tot int64\n",
      "Bwd IAT Mean int64\n",
      "Bwd IAT Std int64\n",
      "Bwd IAT Max int64\n",
      "Bwd IAT Min int64\n",
      "Fwd PSH Flags int64\n",
      "Bwd PSH Flags int64\n",
      "Fwd URG Flags int64\n",
      "Bwd URG Flags int64\n",
      "Fwd Header Len int64\n",
      "Bwd Header Len int64\n",
      "Fwd Pkts/s float64\n",
      "Bwd Pkts/s int64\n",
      "Pkt Len Min int64\n",
      "Pkt Len Max int64\n",
      "Pkt Len Mean int64\n",
      "Pkt Len Std int64\n",
      "Pkt Len Var int64\n",
      "FIN Flag Cnt int64\n",
      "SYN Flag Cnt int64\n",
      "RST Flag Cnt int64\n",
      "PSH Flag Cnt int64\n",
      "ACK Flag Cnt int64\n",
      "URG Flag Cnt int64\n",
      "CWE Flag Count int64\n",
      "ECE Flag Cnt int64\n",
      "Down/Up Ratio int64\n",
      "Pkt Size Avg int64\n",
      "Fwd Seg Size Avg int64\n",
      "Bwd Seg Size Avg int64\n",
      "Fwd Byts/b Avg int64\n",
      "Fwd Pkts/b Avg int64\n",
      "Fwd Blk Rate Avg int64\n",
      "Bwd Byts/b Avg int64\n",
      "Bwd Pkts/b Avg int64\n",
      "Bwd Blk Rate Avg int64\n",
      "Subflow Fwd Pkts int64\n",
      "Subflow Fwd Byts int64\n",
      "Subflow Bwd Pkts int64\n",
      "Subflow Bwd Byts int64\n",
      "Init Fwd Win Byts int64\n",
      "Init Bwd Win Byts int64\n",
      "Fwd Act Data Pkts int64\n",
      "Fwd Seg Size Min int64\n",
      "Active Mean int64\n",
      "Active Std int64\n",
      "Active Max int64\n",
      "Active Min int64\n",
      "Idle Mean float64\n",
      "Idle Std float64\n",
      "Idle Max int64\n",
      "Idle Min int64\n"
     ]
    }
   ],
   "source": [
    "for col, dtype in x_columns.items():\n",
    "    print(col, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinar datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos todos los datasets seleccionados en un sólo dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-14-2018.csv\n",
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-15-2018.csv\n",
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-16-2018.csv\n",
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-21-2018.csv\n",
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-22-2018.csv\n",
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-23-2018.csv\n",
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\02-28-2018.csv\n",
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-01-2018.csv\n",
      "Dataset concatenado: c:\\Users\\isard\\Desktop\\AI-for-Traffic-network-classify\\datasets\\03-02-2018.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for dataset in datasets_selected:\n",
    "    current_df = pd.read_csv(dataset, sep=',', low_memory=False, na_values=NA_VAL, nrows=N_ROWS)\n",
    "    df = pd.concat([df, current_df], ignore_index=True)\n",
    "    print(f\"Dataset concatenado: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720000, 80)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar encabezados repetidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar encabezados repetidos\n",
    "df = df[df['Label'] != 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719991, 80)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719991, 80)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir etiquetas a números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear instancia del codificador\n",
    "le = LabelEncoder()\n",
    "# Aplicar LabelEncoder sobre la columna 'Label'\n",
    "df['Label'] = le.fit_transform(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  9,  6,  8,  7,  5,  4,  2,  3, 10,  1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignar tipo correspondiente a cada una de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna Dst Port actualizada: float64\n",
      "Columna Protocol actualizada: float64\n",
      "Columna Timestamp actualizada: object\n",
      "Columna Flow Duration actualizada: float64\n",
      "Columna Tot Fwd Pkts actualizada: float64\n",
      "Columna Tot Bwd Pkts actualizada: float64\n",
      "Columna TotLen Fwd Pkts actualizada: float64\n",
      "Columna TotLen Bwd Pkts actualizada: float64\n",
      "Columna Fwd Pkt Len Max actualizada: float64\n",
      "Columna Fwd Pkt Len Min actualizada: float64\n",
      "Columna Fwd Pkt Len Mean actualizada: float64\n",
      "Columna Fwd Pkt Len Std actualizada: float64\n",
      "Columna Bwd Pkt Len Max actualizada: float64\n",
      "Columna Bwd Pkt Len Min actualizada: float64\n",
      "Columna Bwd Pkt Len Mean actualizada: float64\n",
      "Columna Bwd Pkt Len Std actualizada: float64\n",
      "Columna Flow Byts/s actualizada: float64\n",
      "Columna Flow Pkts/s actualizada: float64\n",
      "Columna Flow IAT Mean actualizada: float64\n",
      "Columna Flow IAT Std actualizada: float64\n",
      "Columna Flow IAT Max actualizada: float64\n",
      "Columna Flow IAT Min actualizada: float64\n",
      "Columna Fwd IAT Tot actualizada: float64\n",
      "Columna Fwd IAT Mean actualizada: float64\n",
      "Columna Fwd IAT Std actualizada: float64\n",
      "Columna Fwd IAT Max actualizada: float64\n",
      "Columna Fwd IAT Min actualizada: float64\n",
      "Columna Bwd IAT Tot actualizada: float64\n",
      "Columna Bwd IAT Mean actualizada: float64\n",
      "Columna Bwd IAT Std actualizada: float64\n",
      "Columna Bwd IAT Max actualizada: float64\n",
      "Columna Bwd IAT Min actualizada: float64\n",
      "Columna Fwd PSH Flags actualizada: float64\n",
      "Columna Bwd PSH Flags actualizada: float64\n",
      "Columna Fwd URG Flags actualizada: float64\n",
      "Columna Bwd URG Flags actualizada: float64\n",
      "Columna Fwd Header Len actualizada: float64\n",
      "Columna Bwd Header Len actualizada: float64\n",
      "Columna Fwd Pkts/s actualizada: float64\n",
      "Columna Bwd Pkts/s actualizada: float64\n",
      "Columna Pkt Len Min actualizada: float64\n",
      "Columna Pkt Len Max actualizada: float64\n",
      "Columna Pkt Len Mean actualizada: float64\n",
      "Columna Pkt Len Std actualizada: float64\n",
      "Columna Pkt Len Var actualizada: float64\n",
      "Columna FIN Flag Cnt actualizada: float64\n",
      "Columna SYN Flag Cnt actualizada: float64\n",
      "Columna RST Flag Cnt actualizada: float64\n",
      "Columna PSH Flag Cnt actualizada: float64\n",
      "Columna ACK Flag Cnt actualizada: float64\n",
      "Columna URG Flag Cnt actualizada: float64\n",
      "Columna CWE Flag Count actualizada: float64\n",
      "Columna ECE Flag Cnt actualizada: float64\n",
      "Columna Down/Up Ratio actualizada: float64\n",
      "Columna Pkt Size Avg actualizada: float64\n",
      "Columna Fwd Seg Size Avg actualizada: float64\n",
      "Columna Bwd Seg Size Avg actualizada: float64\n",
      "Columna Fwd Byts/b Avg actualizada: float64\n",
      "Columna Fwd Pkts/b Avg actualizada: float64\n",
      "Columna Fwd Blk Rate Avg actualizada: float64\n",
      "Columna Bwd Byts/b Avg actualizada: float64\n",
      "Columna Bwd Pkts/b Avg actualizada: float64\n",
      "Columna Bwd Blk Rate Avg actualizada: float64\n",
      "Columna Subflow Fwd Pkts actualizada: float64\n",
      "Columna Subflow Fwd Byts actualizada: float64\n",
      "Columna Subflow Bwd Pkts actualizada: float64\n",
      "Columna Subflow Bwd Byts actualizada: float64\n",
      "Columna Init Fwd Win Byts actualizada: float64\n",
      "Columna Init Bwd Win Byts actualizada: float64\n",
      "Columna Fwd Act Data Pkts actualizada: float64\n",
      "Columna Fwd Seg Size Min actualizada: float64\n",
      "Columna Active Mean actualizada: float64\n",
      "Columna Active Std actualizada: float64\n",
      "Columna Active Max actualizada: float64\n",
      "Columna Active Min actualizada: float64\n",
      "Columna Idle Mean actualizada: float64\n",
      "Columna Idle Std actualizada: float64\n",
      "Columna Idle Max actualizada: float64\n",
      "Columna Idle Min actualizada: float64\n"
     ]
    }
   ],
   "source": [
    "for col1, dtype1 in df_copy.dtypes.to_dict().items():\n",
    "    for col2, dtype2 in x_columns.items():\n",
    "        if col2 == col1:\n",
    "            # Si la columna es numérica, convertir a float64\n",
    "            if np.issubdtype(dtype2, np.number):\n",
    "                df_copy[col1] = pd.to_numeric(df_copy[col1], errors='coerce').astype('float64')\n",
    "            else:\n",
    "                df_copy[col1] = df_copy[col1].astype(dtype2)\n",
    "            print(f\"Columna {col1} actualizada: {df_copy[col1].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversión de timestamp a formato legible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%d/%m/%Y %H:%M:%S', errors='coerce') #convertimos la timestamp a formato fecha de pandas\n",
    "df['Timestamp'] = np.sin(2*math.pi*df['Timestamp'].dt.hour/24)  # convertimos la fecha en un ciclo legible para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719991, 80)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dst Port          object\n",
       "Protocol          object\n",
       "Timestamp        float64\n",
       "Flow Duration     object\n",
       "Tot Fwd Pkts      object\n",
       "                  ...   \n",
       "Idle Mean         object\n",
       "Idle Std          object\n",
       "Idle Max          object\n",
       "Idle Min          object\n",
       "Label              int64\n",
       "Length: 80, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportación del dataframe en formato CSV y parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV guardado como clean_dataset.csv\n",
      "Archivo CSV guardado como clean_dataset.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>Protocol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>112641719</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320859.5</td>\n",
       "      <td>139.300036</td>\n",
       "      <td>56320958</td>\n",
       "      <td>56320761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>112641466</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320733.0</td>\n",
       "      <td>114.551299</td>\n",
       "      <td>56320814</td>\n",
       "      <td>56320652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>112638623</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56319311.5</td>\n",
       "      <td>301.934596</td>\n",
       "      <td>56319525</td>\n",
       "      <td>56319098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>6453966</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1239</td>\n",
       "      <td>2273</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>8804066</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1143</td>\n",
       "      <td>2209</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dst Port Protocol  Timestamp Flow Duration Tot Fwd Pkts Tot Bwd Pkts  \\\n",
       "0         0        0   0.866025     112641719            3            0   \n",
       "1         0        0   0.866025     112641466            3            0   \n",
       "2         0        0   0.866025     112638623            3            0   \n",
       "3        22        6   0.866025       6453966           15           10   \n",
       "4        22        6   0.866025       8804066           14           11   \n",
       "\n",
       "  TotLen Fwd Pkts TotLen Bwd Pkts Fwd Pkt Len Max Fwd Pkt Len Min  ...  \\\n",
       "0               0               0               0               0  ...   \n",
       "1               0               0               0               0  ...   \n",
       "2               0               0               0               0  ...   \n",
       "3            1239            2273             744               0  ...   \n",
       "4            1143            2209             744               0  ...   \n",
       "\n",
       "  Active Mean Active Std Active Max Active Min   Idle Mean    Idle Std  \\\n",
       "0         0.0        0.0          0          0  56320859.5  139.300036   \n",
       "1         0.0        0.0          0          0  56320733.0  114.551299   \n",
       "2         0.0        0.0          0          0  56319311.5  301.934596   \n",
       "3         0.0        0.0          0          0         0.0         0.0   \n",
       "4         0.0        0.0          0          0         0.0         0.0   \n",
       "\n",
       "   Idle Max  Idle Min Label Protocol   \n",
       "0  56320958  56320761     0         0  \n",
       "1  56320814  56320652     0         0  \n",
       "2  56319525  56319098     0         0  \n",
       "3         0         0     0         6  \n",
       "4         0         0     0         6  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Protocol \"] = df[\"Protocol\"].astype(int)\n",
    "df[\"Dst Port\"] = df[\"Dst Port\"].astype(int)\n",
    "# Guardar en csv\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Archivo CSV guardado como {OUTPUT_CSV}\")\n",
    "\n",
    "# Guardar en Parquet\n",
    "# df.to_parquet(OUTPUT_PARQUET, index=False)  # No está funcionando\n",
    "# print(f\"Archivo CSV guardado como {OUTPUT_PARQUET}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def find_datasets_with_same_header():\\n    headers = {}\\n    same_files = {}\\n\\n    for file in DATASETS:\\n        with open(file, newline=\\'\\', encoding=\\'utf-8\\') as f:\\n            header = tuple(next(csv.reader(f), None))\\n            if header:\\n                if header in headers:\\n                    headers[header].append(file)\\n                else:\\n                    headers[header] = [file]\\n    print(\"Archivos con headers distintos:\", tuple(headers.values())[1])\\n    return tuple(headers.values())[0]\\n\\nDATASETS = find_datasets_with_same_header()'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def find_datasets_with_same_header():\n",
    "    headers = {}\n",
    "    same_files = {}\n",
    "\n",
    "    for file in DATASETS:\n",
    "        with open(file, newline='', encoding='utf-8') as f:\n",
    "            header = tuple(next(csv.reader(f), None))\n",
    "            if header:\n",
    "                if header in headers:\n",
    "                    headers[header].append(file)\n",
    "                else:\n",
    "                    headers[header] = [file]\n",
    "    print(\"Archivos con headers distintos:\", tuple(headers.values())[1])\n",
    "    return tuple(headers.values())[0]\n",
    "\n",
    "DATASETS = find_datasets_with_same_header()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4188301155.py, line 12)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\"\"\"def mixed_types_columns(df):\n",
    "    \"\"\"\n",
    "    # Recorre todas las columnas del DataFrame y devuelve un diccionario\n",
    "    # con las columnas que contienen más de un tipo de dato.\n",
    "\n",
    "    # Args:\n",
    "    #     df (pd.DataFrame): El DataFrame a analizar.\n",
    "\n",
    "    # Returns:\n",
    "    #     dict: Un diccionario con nombres de columnas como claves,\n",
    "    #           y otro diccionario con los tipos de datos y sus cantidades como valores.\n",
    "    \"\"\"\n",
    "    mixed_types_columns = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        types = {}\n",
    "        for val in df[col]:\n",
    "            typeVal = type(val)\n",
    "            types[typeVal] = types.get(typeVal, 0) + 1\n",
    "\n",
    "        if len(types) > 1:\n",
    "            mixed_types_columns[col] = types\n",
    "\n",
    "    return mixed_types_columns\n",
    "\n",
    "df = pd.read_csv('merged_output.csv')\n",
    "mixed_types_columns = mixed_types_columns(df)\n",
    "for col, types in mixed_types_columns.items():\n",
    "    print(f\"Columna: {col}\")\n",
    "    for typeVal, quantity in types.items():\n",
    "        print(f\"  type: {typeVal.__name__}, Cantidad: {quantity}\")\n",
    "    print()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"columns_lengths = []\n",
    "\n",
    "# Obtener número de columnas por dataset\n",
    "for dataset in DATASETS:\n",
    "    columns_length = len(pd.read_csv(dataset, nrows=1).dtypes)\n",
    "    columns_lengths.append(columns_length)\n",
    "\n",
    "# Obtener grupo de características más largo\n",
    "for dataset in DATASETS:\n",
    "    df = pd.read_csv(dataset, nrows=1)\n",
    "    columns_length = len(df.dtypes)\n",
    "    if columns_length == max(columns_lengths):\n",
    "        X_columns = df.dtypes.to_dict()\n",
    "        if 'Label' in X_columns:\n",
    "            X_columns.pop('Label')\n",
    "print(len(X_columns))\n",
    "for column, type in X_columns.items():\n",
    "    print(column, type)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
